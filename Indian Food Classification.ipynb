{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image , ImageOps\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  653\n",
      "8  608\n",
      "11  466\n",
      "20  374\n",
      "17  207\n",
      "10  323\n",
      "5  383\n",
      "12  1741\n",
      "2  573\n",
      "19  LoL\n",
      "273\n",
      "9  834\n",
      "14  568\n",
      "18  714\n",
      "15  248\n",
      "13  206\n",
      "4  373\n",
      "16  279\n",
      "6  231\n",
      "1  177\n",
      "7  381\n"
     ]
    }
   ],
   "source": [
    "# Creation of Test data\n",
    "input_folder = './ResizedImg'\n",
    "\n",
    "x_train =[]\n",
    "y_train =[]\n",
    "x_test  =[]\n",
    "y_test  =[]\n",
    "\n",
    "percent = 0.6\n",
    "\n",
    "for classes in os.listdir(input_folder):\n",
    "    print(classes,' ',end = '')\n",
    "    imagePath = input_folder+'/'+classes\n",
    "    class_data = []\n",
    "    for images in os.listdir(imagePath):\n",
    "        try:\n",
    "            im = Image.open(imagePath+'/'+images)\n",
    "            imgMat = np.array(im)\n",
    "            if imgMat.shape == (224,224,3): \n",
    "                class_data.append(imgMat)\n",
    "        except:\n",
    "            print('LoL')\n",
    "    print(len(class_data))\n",
    "    sizeofclass = len(class_data)\n",
    "    \n",
    "    num_of_Train_exp = math.floor(sizeofclass*(percent))\n",
    "    \n",
    "    X_train = class_data[0:num_of_Train_exp]\n",
    "    X_test = class_data[num_of_Train_exp:]\n",
    "    \n",
    "    Y_train = [int(classes)-1]*len(X_train)\n",
    "    Y_test = [int(classes)-1]*len(X_test)\n",
    "    \n",
    "    x_train = x_train + X_train\n",
    "    y_train = y_train + Y_train\n",
    "    x_test = x_test + X_test\n",
    "    y_test = y_test + Y_test\n",
    "\n",
    "del X_train\n",
    "del Y_train\n",
    "del X_test\n",
    "del Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5755\n",
      "5755\n",
      "3857\n",
      "3857\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "\n",
    "print(len(x_test))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(zip(x_train,y_train))\n",
    "random.shuffle(a)\n",
    "x_train , y_train = zip(*a)\n",
    "\n",
    "a = list(zip(x_test,y_test))\n",
    "random.shuffle(a)\n",
    "x_test , y_test = zip(*a)\n",
    "del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(list(x_train), dtype=np.float16)\n",
    "y_train = np.array(list(y_train), dtype=np.float16)\n",
    "x_test  = np.array(list(x_test), dtype=np.float16)\n",
    "y_test  = np.array(list(y_test), dtype=np.float16)\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, 20)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255;\n",
    "x_test /= 255;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving train and test set in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train.npy',x_train)\n",
    "np.save('y_train.npy',y_train)\n",
    "np.save('x_test.npy',x_test)\n",
    "np.save('y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "x_test  = np.load('x_test.npy')\n",
    "y_test  = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "# img_rows, img_cols ,channel = 224, 224 , 3\n",
    "def createModel1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3,3),strides=1,padding='same',activation='relu',input_shape=(224,224,3)))\n",
    "    model.add(Conv2D(filters=20, kernel_size=(3,3),strides=1,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=9, kernel_size=(1,1),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5,5), strides=5, padding=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1089,activation='relu'))\n",
    "    model.add(Dense(400,activation='relu'))\n",
    "    model.add(Dense(20,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel2():\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(400, activation='relu')(x)\n",
    "    \n",
    "    predictions = Dense(20, activation='softmax')(x)\n",
    "\n",
    "    m = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in m.layers[:249]:\n",
    "        layer.trainable = False\n",
    "    for layer in m.layers[249:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    m.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel3():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(400, activation='relu')(x)\n",
    "    # and a logistic layer -- \n",
    "    predictions = Dense(20, activation='softmax')(x)\n",
    "\n",
    "    m = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in m.layers[:249]:\n",
    "        layer.trainable = False\n",
    "    for layer in m.layers[249:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    m.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols ,channel = 224, 224 , 3\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "def createModel4():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3,3),strides=1,padding='same',activation='relu',input_shape=(224,224,3)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(1,1),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(1,1),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dense(2000,activation='relu'))\n",
    "    model.add(Dense(20,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel5():\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet',input_shape=(224,224,3))\n",
    "    # base_model = VGG16(weights='imagenet', include_top=False)\n",
    "    base_model.summary()\n",
    "    # x_test = keras.utils.np_utils.to_categorical(x_test,20)\n",
    "    # y_test = keras.utils.np_utils.to_categorical(y_test,20)\n",
    "    # # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(400, activation='relu')(x)\n",
    "    # and a logistic layer -- \n",
    "    predictions = Dense(20, activation='softmax')(x)\n",
    "\n",
    "    m = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in m.layers[:47]:\n",
    "        layer.trainable = False\n",
    "    for layer in m.layers[48:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    m.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5755 samples, validate on 3857 samples\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "batch_size = 50\n",
    "num_classes = 20\n",
    "epochs = 3\n",
    "model = createModel4()\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "score = m.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garbage Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_TEST_DATA = []\n",
    "# Y_TEST_DATA = []\n",
    "\n",
    "# input_folder_test = './ResizedImg/test'\n",
    "# for classes in os.listdir(input_folder):\n",
    "#     imagePath = input_folder+'/'+classes\n",
    "#     for images in os.listdir(imagePath):\n",
    "#         im = Image.open(imagePath+'/'+images)\n",
    "#         imgMat = np.array(im)\n",
    "#         X_TEST_DATA.append(imgMat)\n",
    "#         Y_TEST_DATA.append(classes)\n",
    "\n",
    "# X_TRAIN_DATA = []\n",
    "# Y_TRAIN_DATA = []\n",
    "\n",
    "# input_folder_test = './ResizedImg/train'\n",
    "# for classes in os.listdir(input_folder):\n",
    "#     imagePath = input_folder+'/'+classes\n",
    "#     for images in os.listdir(imagePath):\n",
    "#         im = Image.open(imagePath+'/'+images)\n",
    "#         imgMat = np.array(im)\n",
    "#         X_TRAIN_DATA.append(imgMat)\n",
    "#         Y_TRAIN_DATA.append(classes)\n",
    "\n",
    "# x_train_F = [item for sublist in x_train for item in sublist]\n",
    "# y_train_F = [item for sublist in y_train for item in sublist]\n",
    "# x_test_F  = [item for sublist in x_test for item in sublist]\n",
    "# y_test_F  = [item for sublist in y_test for item in sublist]\n",
    "\n",
    "# x_train_w = []\n",
    "# y_train_w = []\n",
    "# x_test_w = []\n",
    "# y_test_w = []\n",
    "\n",
    "# for img in x_train:\n",
    "#     try:\n",
    "#         if img.shape == (224,224,3):\n",
    "#             x_train_w.append(np.array(img))\n",
    "#         else:\n",
    "#             print('wrong',img.shape)\n",
    "#     except:\n",
    "#         print('LOL')\n",
    "\n",
    "# for img in y_train:\n",
    "#     try:\n",
    "#         if img.shape == (224,224,3):\n",
    "#             y_train_w.append(np.array(img))\n",
    "#         else:\n",
    "#             print('wrong',img.shape)\n",
    "#     except:\n",
    "#         print('LOL')\n",
    "\n",
    "# for img in x_test:\n",
    "#     try:\n",
    "#         if img.shape == (224,224,3):\n",
    "#             x_test_w.append(np.array(img))\n",
    "#         else:\n",
    "#             print('wrong',img.shape)\n",
    "#     except:\n",
    "#         print('LOL')\n",
    "\n",
    "# for img in y_test:\n",
    "#     try:\n",
    "#         if img.shape == (224,224,3):\n",
    "#             y_test_w.append(np.array(img))\n",
    "#         else:\n",
    "#             print('wrong',img.shape)\n",
    "#     except:\n",
    "#         print('LOL')\n",
    "\n",
    "# x_train = np.array(x_train_w, dtype=np.float32)\n",
    "# y_train = np.array(y_train_w, dtype=np.float32)\n",
    "# x_test  = np.array(x_test_w, dtype=np.float32)\n",
    "# y_test  = np.array(y_test_w, dtype=np.float32)\n",
    "\n",
    "# img = Image.fromarray(np.array(X_train[0]))\n",
    "# img\n",
    "\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# the data, split between train and test sets\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# print(x_train[0])\n",
    "# print(len(x_train[0]))\n",
    "# im = Image.open(x_train[0])\n",
    "# im.show()\n",
    "# print('before changing')\n",
    "# print('x_train shape:', x_train.shape)\n",
    "# print(x_train.shape[0], 'train samples')\n",
    "# print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "# if K.image_data_format() == 'channels_first':\n",
    "#     x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "#     x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "#     input_shape = (1, img_rows, img_cols)\n",
    "#     print(\"hola\")\n",
    "# else:\n",
    "#     print(\"hola8\")\n",
    "#     x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "#     x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "#     input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# print(x_train[0])\n",
    "# print(len(x_train[0][0][0]))\n",
    "# print(x_train[0].shape)\n",
    "# print(np.zeros((3,3,1)))\n",
    "\n",
    "# im1 = Image.open(\"b.jpeg\").convert('LA')\n",
    "# im1 = Image.open(\"b.jpeg\")\n",
    "# im2=ImageOps.grayscale(im1)\n",
    "# Arr1 = np.array(im1)\n",
    "# Arr2 = np.array(im2)\n",
    "# print('shape of image is',Arr.shape,' value are ',Arr[0][0])\n",
    "# Arr.show()\n",
    "# img = Image.fromarray(Arr)\n",
    "# img.show()    \n",
    "\n",
    "# print(x_train[0].type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67423311, 0.0430721 ],\n",
       "       [0.57733056, 0.40607748],\n",
       "       [0.16510067, 0.72085671],\n",
       "       [0.56879062, 0.70950606],\n",
       "       [0.6532192 , 0.54556054],\n",
       "       [0.88227646, 0.6845853 ],\n",
       "       [0.45780046, 0.50631469],\n",
       "       [0.34744537, 0.40783336],\n",
       "       [0.21499988, 0.44303972],\n",
       "       [0.0415734 , 0.76062591]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    " keras.utils.np_utils.to_categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
