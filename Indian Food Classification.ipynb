{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Model,load_model\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input,Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image , ImageOps\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import densenet\n",
    "import os\n",
    "from shutil import copyfile\n",
    "from tensorflow.python.framework import graph_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1918658016147652860\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 582994049396728377\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 18185636121376598658\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  8  60  11  44  20  17  47  10  36  52  30  5  49  12  50  61  2  46  19  LoL\n",
      "9  25  48  62  55  LoL\n",
      "29  14  18  21  26  40  33  15  22  27  53  13  4  63  16  28  32  39  35  37  6  56  54  1  7  41  58  23  64  43  31  45  65  38  34  LoL\n",
      "59  42  57  24  51  "
     ]
    }
   ],
   "source": [
    "# Creation of Test data\n",
    "input_folder = './DataSet'\n",
    "\n",
    "x_train =[]\n",
    "y_train =[]\n",
    "x_test  =[]\n",
    "y_test  =[]\n",
    "\n",
    "percent = 0.7\n",
    "\n",
    "for classes in os.listdir(input_folder):\n",
    "    print(classes,' ',end = '')\n",
    "    imagePath = input_folder+'/'+classes\n",
    "    class_data = []\n",
    "    class_data_name = []\n",
    "    for images in os.listdir(imagePath):\n",
    "        try:\n",
    "            im = Image.open(imagePath+'/'+images)\n",
    "            imgMat = np.array(im)\n",
    "            if imgMat.shape == (224,224,3): \n",
    "                class_data.append(imgMat)\n",
    "                class_data_name.append(imagePath+'/'+images)\n",
    "        except:\n",
    "            print('LoL')\n",
    "#     print(len(class_data))\n",
    "    sizeofclass = len(class_data)\n",
    "    \n",
    "    num_of_Train_exp = math.floor(sizeofclass*(percent))\n",
    "    \n",
    "    X_train = class_data[0:num_of_Train_exp]\n",
    "    X_test = class_data[num_of_Train_exp:]\n",
    "    \n",
    "    TrainSet = class_data_name[0 : num_of_Train_exp]\n",
    "    ValidationSet = class_data_name[num_of_Train_exp : ]\n",
    "\n",
    "    directory = './DATASET/Training/'+classes\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    i = 1\n",
    "    for imagesPath in TrainSet:\n",
    "        dest2 = directory +'/'+str(i)+'.jpg'\n",
    "        copyfile(imagesPath, dest2)\n",
    "        i = i + 1\n",
    "    \n",
    "    \n",
    "    directory = './DATASET/Validation/'+classes\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    i = 1\n",
    "    for imagesPath in ValidationSet:\n",
    "        dest2 = directory +'/'+str(i)+'.jpg'\n",
    "        copyfile(imagesPath, dest2)\n",
    "        i = i + 1\n",
    "\n",
    "#     Y_train = [int(classes)-1]*len(X_train)\n",
    "#     Y_test = [int(classes)-1]*len(X_test)\n",
    "    \n",
    "#     x_train = x_train + X_train\n",
    "#     y_train = y_train + Y_train\n",
    "#     x_test = x_test + X_test\n",
    "#     y_test = y_test + Y_test\n",
    "\n",
    "# del X_train\n",
    "# del Y_train\n",
    "# del X_test\n",
    "# del Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "# img_rows, img_cols ,channel = 224, 224 , 3\n",
    "def createModel1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3,3),strides=1,padding='same',activation='relu',input_shape=(224,224,3)))\n",
    "    model.add(Conv2D(filters=20, kernel_size=(3,3),strides=1,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=9, kernel_size=(1,1),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5,5), strides=5, padding=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1089,activation='relu'))\n",
    "    model.add(Dense(400,activation='relu'))\n",
    "    model.add(Dense(20,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel2():\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "    x = base_model.output\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(400, activation='relu')(x)\n",
    "    \n",
    "    predictions = Dense(20, activation='softmax')(x)\n",
    "\n",
    "    m = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in m.layers[:249]:\n",
    "        layer.trainable = False\n",
    "    for layer in m.layers[249:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    m.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel3():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(400, activation='relu')(x)\n",
    "    # and a logistic layer -- \n",
    "    predictions = Dense(20, activation='softmax')(x)\n",
    "\n",
    "    m = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in m.layers[:249]:\n",
    "        layer.trainable = False\n",
    "    for layer in m.layers[249:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    m.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols ,channel = 224, 224 , 3\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "def createModel4():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3,3),strides=1,padding='same',activation='relu',input_shape=(224,224,3)))\n",
    "    model.add(Conv2D(filters=1096, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=2096, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=2096, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=3096, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=3096, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=4096, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=5012, kernel_size=(1,1),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=5012, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=6012, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=7017, kernel_size=(1,1),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=1096, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=1096, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=2096, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=3096, kernel_size=(1,1),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=3096, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=4096, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    #model.add(Conv2D(filters=128, kernel_size=(1,1),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(5096,activation='relu'))\n",
    "    model.add(Dense(2000,activation='relu'))\n",
    "    model.add(Dense(20,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols ,channel = 224, 224 , 3\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "def createMode10():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3,3),strides=1,padding='same',activation='relu',input_shape=(224,224,3)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(1,1),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(1,1),strides=1,padding='same',activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "    model.add(Dense(2000,activation='relu'))\n",
    "    model.add(Dense(20,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel5():\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet',input_shape=(224,224,3))\n",
    "\n",
    "    # # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(400, activation='relu')(x)\n",
    "    # and a logistic layer -- \n",
    "    predictions = Dense(20, activation='softmax')(x)\n",
    "\n",
    "    m = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in m.layers[-3:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    m.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel6():\n",
    "    #input_format = Input(shape=(224,224,3),name = 'image_input')\n",
    "    #base_model = MobileNetV2(weights='imagenet', include_top=False,input_tensor=input_format)\n",
    "    base_model= keras.applications.densenet.DenseNet121(include_top=False,input_shape=(224,224,3))\n",
    "    # add a global spatial average pooling layer\n",
    "        \n",
    "    x = base_model.output\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(400, activation='relu')(x)\n",
    "    # and a logistic layer -- \n",
    "    predictions = Dense(65, activation='softmax',name='output')(x)\n",
    "\n",
    "    m = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    for layer in m.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    for layer in m.layers[-2:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "\n",
    "    m.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14737 images belonging to 65 classes.\n",
      "Found 6344 images belonging to 65 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './DATASET/Training',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=10,\n",
    "        save_to_dir='./Augmented/Training',\n",
    "        save_prefix='aug', \n",
    "        save_format='jpg',\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        './DATASET/Validation',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=10,\n",
    "        save_to_dir='./Augmented/Validation',\n",
    "        save_prefix='aug', \n",
    "        save_format='jpg',\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "\n",
    "# i = 0\n",
    "# for batch in train_generator:\n",
    "#     i += 1\n",
    "#     if i > 20:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6344 images belonging to 65 classes.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262161 images belonging to 11 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuldeep/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/PIL/Image.py:969: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "broken data stream when reading image file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-980870f62aa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         shuffle=False)  # keep data in same order as labels\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             verbose=verbose)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;31m# Compatibility with the generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(uid, i)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mat\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mi\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \"\"\"\n\u001b[0;32m--> 401\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[1;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    224\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \", \".join(_PIL_INTERPOLATION_METHODS.keys())))\n\u001b[1;32m    125\u001b[0m             \u001b[0mresample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_PIL_INTERPOLATION_METHODS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth_height_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1802\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mLOAD_TRUNCATED_IMAGES\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# still raised if decoder fails to return anything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0mraise_ioerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mraise_ioerror\u001b[0;34m(error)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"decoder error %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" when reading image file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: broken data stream when reading image file"
     ]
    }
   ],
   "source": [
    "generator = test_datagen.flow_from_directory(\n",
    "        './',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=10,\n",
    "        class_mode=None,  # only data, no labels\n",
    "        shuffle=False)  # keep data in same order as labels\n",
    "\n",
    "probabilities = model.predict_generator(generator, 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 24) 648         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 24) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 24) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 224, 224, 48) 1152        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 224, 224, 48) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 224, 224, 48) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 224, 224, 12) 5184        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 224, 224, 36) 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 224, 224, 36) 144         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 224, 224, 36) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 224, 224, 48) 1728        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 224, 224, 48) 192         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 224, 224, 48) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 224, 224, 12) 5184        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 224, 224, 48) 0           concatenate_1[0][0]              \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 224, 224, 48) 192         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 224, 224, 48) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 224, 224, 24) 1152        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 112, 112, 24) 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 112, 112, 24) 96          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 112, 112, 24) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 112, 112, 48) 1152        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 112, 112, 48) 192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 112, 112, 48) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 112, 112, 12) 5184        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 112, 112, 36) 0           average_pooling2d_1[0][0]        \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 112, 112, 36) 144         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 112, 112, 36) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 112, 112, 48) 1728        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 112, 112, 48) 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 112, 112, 48) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 112, 112, 12) 5184        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 48) 0           concatenate_3[0][0]              \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 112, 112, 48) 192         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 112, 112, 48) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 112, 112, 24) 1152        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 56, 56, 24)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 56, 56, 24)   96          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 56, 56, 24)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 56, 56, 48)   1152        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 56, 56, 48)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 56, 56, 48)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 56, 56, 12)   5184        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 56, 56, 36)   0           average_pooling2d_2[0][0]        \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 56, 56, 36)   144         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 56, 56, 36)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 56, 56, 48)   1728        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 56, 56, 48)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 56, 56, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 56, 56, 12)   5184        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 56, 56, 48)   0           concatenate_5[0][0]              \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 56, 56, 48)   192         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 56, 56, 48)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 48)           0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 65)           3185        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 48,329\n",
      "Trainable params: 47,105\n",
      "Non-trainable params: 1,224\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1474/1474 [==============================] - 10045s 7s/step - loss: 3.8333 - acc: 0.1229 - val_loss: 3.6801 - val_acc: 0.1472\n",
      "\n",
      "Epoch 00001: saving model to training_4/Checkpoints/cp-0001.ckpt\n",
      "Epoch 2/10\n",
      "1474/1474 [==============================] - 10007s 7s/step - loss: 3.5539 - acc: 0.1562 - val_loss: 3.6972 - val_acc: 0.1561\n",
      "\n",
      "Epoch 00002: saving model to training_4/Checkpoints/cp-0002.ckpt\n",
      "Epoch 3/10\n",
      "1474/1474 [==============================] - 9896s 7s/step - loss: 3.4094 - acc: 0.1810 - val_loss: 3.7558 - val_acc: 0.1557\n",
      "\n",
      "Epoch 00003: saving model to training_4/Checkpoints/cp-0003.ckpt\n",
      "Epoch 4/10\n",
      "1474/1474 [==============================] - 9910s 7s/step - loss: 3.3004 - acc: 0.1956 - val_loss: 3.2008 - val_acc: 0.2133\n",
      "\n",
      "Epoch 00004: saving model to training_4/Checkpoints/cp-0004.ckpt\n",
      "Epoch 5/10\n",
      "1474/1474 [==============================] - 9979s 7s/step - loss: 3.2259 - acc: 0.2066 - val_loss: 3.4081 - val_acc: 0.1734\n",
      "\n",
      "Epoch 00005: saving model to training_4/Checkpoints/cp-0005.ckpt\n",
      "Epoch 6/10\n",
      "1474/1474 [==============================] - 10040s 7s/step - loss: 3.1570 - acc: 0.2196 - val_loss: 3.5693 - val_acc: 0.2108\n",
      "\n",
      "Epoch 00006: saving model to training_4/Checkpoints/cp-0006.ckpt\n",
      "Epoch 7/10\n",
      "1474/1474 [==============================] - 10080s 7s/step - loss: 3.1050 - acc: 0.2274 - val_loss: 3.2999 - val_acc: 0.2213\n",
      "\n",
      "Epoch 00007: saving model to training_4/Checkpoints/cp-0007.ckpt\n",
      "Epoch 8/10\n",
      "1474/1474 [==============================] - 10084s 7s/step - loss: 3.0532 - acc: 0.2394 - val_loss: 3.1107 - val_acc: 0.2434\n",
      "\n",
      "Epoch 00008: saving model to training_4/Checkpoints/cp-0008.ckpt\n",
      "Epoch 9/10\n",
      "1474/1474 [==============================] - 9927s 7s/step - loss: 3.0110 - acc: 0.2467 - val_loss: 2.9917 - val_acc: 0.2546\n",
      "\n",
      "Epoch 00009: saving model to training_4/Checkpoints/cp-0009.ckpt\n",
      "Epoch 10/10\n",
      "1474/1474 [==============================] - 9920s 7s/step - loss: 2.9816 - acc: 0.2508 - val_loss: 2.9699 - val_acc: 0.2741\n",
      "\n",
      "Epoch 00010: saving model to training_4/Checkpoints/cp-0010.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50d8e89390>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config\n",
    "tf.reset_default_graph()\n",
    "K.clear_session()\n",
    "epochs = 10\n",
    "\n",
    "checkpoint_path = \"training_4/Checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,period=1)\n",
    "\n",
    "# model = createModel6()\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "image_dim = (224, 224, 3)\n",
    "\n",
    "model = densenet.DenseNet(classes=65, input_shape=image_dim, depth=19, growth_rate=12,bottleneck=True, reduction=0.5)\n",
    "print(model.summary())\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adadelta\", metrics=[\"accuracy\"])\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "#         steps_per_epoch=100,\n",
    "        callbacks=[cp_callback],\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "#         validation_steps=200\n",
    "        \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet.DenseNet(classes=65, input_shape=(224,224,3), depth=19, growth_rate=12,bottleneck=True, reduction=0.5)\n",
    "model.load_weights('training_4/Checkpoints/cp-0010.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('newModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635\n"
     ]
    }
   ],
   "source": [
    "print(len(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.9698621852025107\n",
      "Test accuracy: 0.27411728183425316\n"
     ]
    }
   ],
   "source": [
    "#score = model.evaluate(train_generator, validation_data)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adadelta\", metrics=[\"accuracy\"])\n",
    "score= model.evaluate_generator(validation_generator, max_queue_size=10)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-04ae2a7ad703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "model.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted= model.predict_generator(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted[0]\n",
    "#y_pred = np.rint(predicted)\n",
    "#y_true = validation_generator.classes\n",
    "#print (classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Bhindi       0.37      0.48      0.42        54\n",
      "         Briyani       0.30      0.22      0.25        97\n",
      "            Naan       0.27      0.60      0.38       140\n",
      "           Halwa       0.23      0.82      0.36       523\n",
      "          Imarti       0.44      0.06      0.11        62\n",
      "   Chole bhatura       0.29      0.22      0.25       171\n",
      "     Daal makhni       0.00      0.00      0.00        75\n",
      "          jalebi       0.00      0.00      0.00        84\n",
      "         Cachuri       0.56      0.08      0.14        63\n",
      "            Kadi       0.41      0.17      0.24       215\n",
      "           Barfi       0.75      0.04      0.07        82\n",
      "           kheer       0.36      0.53      0.43       172\n",
      "           kulfi       0.33      0.05      0.09       113\n",
      "           ladoo       0.00      0.00      0.00        69\n",
      "      Pav bhaaji       0.14      0.03      0.05        61\n",
      "           Momos       0.31      0.06      0.10        65\n",
      "           Papad       0.29      0.12      0.17        78\n",
      "       Ras malai       0.00      0.00      0.00        67\n",
      "            Roti       0.00      0.00      0.00        69\n",
      "            Upma       0.15      0.18      0.16        72\n",
      "       Aloo_gobi       0.00      0.00      0.00        50\n",
      "      Aloo_matar       0.33      0.13      0.18        79\n",
      "      Aloo_methi       0.54      0.61      0.57       196\n",
      "           Bajji       0.27      0.57      0.36        44\n",
      "         Bhatura       0.00      0.00      0.00        58\n",
      "           Bonda       0.39      0.26      0.31        74\n",
      "  Butter_Chicken       0.00      0.00      0.00        48\n",
      "           Chaap       0.00      0.00      0.00        67\n",
      "    Chana_masala       0.27      0.37      0.31        83\n",
      "      chicken_65       0.00      0.00      0.00        70\n",
      "    chole_kulche       0.00      0.00      0.00        65\n",
      "     Dahi_bhalla       0.13      0.10      0.12        69\n",
      "       Dahi_Vada       0.18      0.17      0.17        78\n",
      "             dal       0.26      0.54      0.35       112\n",
      "          Dhokla       0.21      0.13      0.16        82\n",
      "            Dosa       0.00      0.00      0.00        53\n",
      "           iddli       0.25      0.44      0.32        73\n",
      "    Kadai_paneer       0.00      0.00      0.00        78\n",
      "           Kabab       0.33      0.02      0.03        62\n",
      "         Khandvi       0.07      0.05      0.05        66\n",
      "    litti_chokha       0.33      0.64      0.43        90\n",
      "          Maggie       0.00      0.00      0.00        72\n",
      "     Malai_kofta       0.26      0.06      0.09        89\n",
      "    Matar_paneer       0.23      0.43      0.30        90\n",
      "           Modak       0.56      0.24      0.34       115\n",
      "    Palak_Paneer       0.14      0.07      0.09        90\n",
      "        Panipuri       0.16      0.04      0.07        90\n",
      "         Paratha       0.13      0.37      0.19       108\n",
      "            Poha       0.00      0.00      0.00        90\n",
      "           Puttu       0.20      0.11      0.14        90\n",
      "     RajmaChawal       0.17      0.01      0.02        90\n",
      "           Rajma       0.28      0.10      0.15        90\n",
      "      Rasam_Rice       0.00      0.00      0.00        85\n",
      "            Rice       0.00      0.00      0.00        76\n",
      "       RoganJosh       0.14      0.04      0.07        90\n",
      "          Sambar       0.24      0.21      0.23        70\n",
      "          Samosa       0.16      0.19      0.17        90\n",
      "    Shahi_paneer       0.12      0.16      0.13        90\n",
      "       Shrikhand       0.29      0.06      0.09        90\n",
      "      Springroll       0.55      0.13      0.21        90\n",
      "Tandoori_Chicken       0.15      0.05      0.07        81\n",
      "          Thepla       0.67      0.02      0.04        90\n",
      "         Uttapam       0.37      0.50      0.42       115\n",
      "        Vada_pav       0.37      0.92      0.53       183\n",
      "            Vada       0.36      0.54      0.43       251\n",
      "\n",
      "       micro avg       0.27      0.27      0.27      6344\n",
      "       macro avg       0.22      0.18      0.16      6344\n",
      "    weighted avg       0.25      0.27      0.21      6344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from keras.utils import np_utils\n",
    "y_curr = np.zeros(6344)\n",
    "for i in range(0,6344):\n",
    "    index = np.argmax(predicted[i])\n",
    "    y_curr[i] = index\n",
    "\n",
    "y_test= validation_generator.classes\n",
    "\n",
    "cc = ['Bhindi','Briyani','Naan','Halwa', 'Imarti', 'Chole bhatura', 'Daal makhni', 'jalebi', 'Cachuri', 'Kadi', 'Barfi', 'kheer','kulfi', 'ladoo', 'Pav bhaaji', 'Momos', 'Papad', 'Ras malai', 'Roti', 'Upma', 'Aloo_gobi', 'Aloo_matar', 'Aloo_methi', 'Bajji', 'Bhatura', 'Bonda', 'Butter_Chicken', 'Chaap', 'Chana_masala', 'chicken_65', 'chole_kulche', 'Dahi_bhalla', 'Dahi_Vada', 'dal', 'Dhokla', 'Dosa', 'iddli', 'Kadai_paneer', 'Kabab', 'Khandvi', 'litti_chokha', 'Maggie', 'Malai_kofta', 'Matar_paneer', 'Modak', 'Palak_Paneer', 'Panipuri', 'Paratha', 'Poha', 'Puttu', 'RajmaChawal', 'Rajma', 'Rasam_Rice', 'Rice', 'RoganJosh', 'Sambar', 'Samosa', 'Shahi_paneer', 'Shrikhand', 'Springroll', 'Tandoori_Chicken', 'Thepla', 'Uttapam', 'Vada_pav', 'Vada' ]                                           \n",
    "print(classification_report(y_test, y_curr,target_names=cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-bbcbfca725c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AdvanceCV/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 'Got tensor with shape: %s' % str(shape))\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_curr = np.zeros(y_pred.shape)\n",
    "for i in range(0,len(y_pred)):\n",
    "    index = np.argmax(y_pred[i])\n",
    "    y_curr[i][index] = 1\n",
    "\n",
    "target_names = ['Bhindi','Briyani','Naan','Halwa', 'Imarti', 'Chole bhatura', 'Daal makhni', 'jalebi', 'Cachuri', 'Kadi', 'Barfi', 'kheer','kulfi', 'ladoo', 'Pav bhaaji', 'Momos', 'Papad', 'Ras malai', 'Roti', 'Upma', 'Aloo_gobi', 'Aloo_matar', 'Aloo_methi', 'Bajji', 'Bhatura', 'Bonda', 'Butter_Chicken', 'Chaap', 'Chana_masala', 'chicken_65', 'chole_kulche', 'Dahi_bhalla', 'Dahi_Vada', 'dal', 'Dhokla', 'Dosa', 'iddli', 'Kadai_paneer', 'Kabab', 'Khandvi', 'litti_chokha', 'Maggie', 'Malai_kofta', 'Matar_paneer', 'Modak', 'Palak_Paneer', 'Panipuri', 'Paratha', 'Poha', 'Puttu', 'RajmaChawal', 'Rajma', 'Rasam_Rice', 'Rice', 'RoganJosh', 'Sambar', 'Samosa', 'Shahi_paneer', 'Shrikhand', 'Springroll', 'Tandoori_Chicken', 'Thepla', 'Uttapam', 'Vada_pav', 'Vada' ]                                           \n",
    "print(classification_report(y_test, y_curr,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-545d2d336bc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print('Test loss:', score[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print('Test accuracy:', score[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "model = load_model('my_modelF.h5')\n",
    "#score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])\n",
    "print(model.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 1920 variables.\n",
      "INFO:tensorflow:Converted 1920 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./training/my_model.pb'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('saveModel.h5')\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "    \n",
    "    \n",
    "frozen_graph = freeze_session(K.get_session(),output_names=[out.op.name for out in model.outputs])\n",
    "tf.train.write_graph(frozen_graph, \"./training\", \"my_model.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('my_modelFF.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garbage Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_TEST_DATA = []\n",
    "# Y_TEST_DATA = []\n",
    "\n",
    "# input_folder_test = './ResizedImg/test'\n",
    "# for classes in os.listdir(input_folder):\n",
    "#     imagePath = input_folder+'/'+classes\n",
    "#     for images in os.listdir(imagePath):\n",
    "#         im = Image.open(imagePath+'/'+images)\n",
    "#         imgMat = np.array(im)\n",
    "#         X_TEST_DATA.append(imgMat)\n",
    "#         Y_TEST_DATA.append(classes)\n",
    "\n",
    "# X_TRAIN_DATA = []\n",
    "# Y_TRAIN_DATA = []\n",
    "\n",
    "# input_folder_test = './ResizedImg/train'\n",
    "# for classes in os.listdir(input_folder):\n",
    "#     imagePath = input_folder+'/'+classes\n",
    "#     for images in os.listdir(imagePath):\n",
    "#         im = Image.open(imagePath+'/'+images)\n",
    "#         imgMat = np.array(im)\n",
    "#         X_TRAIN_DATA.append(imgMat)\n",
    "#         Y_TRAIN_DATA.append(classes)\n",
    "\n",
    "# x_train_F = [item for sublist in x_train for item in sublist]\n",
    "# y_train_F = [item for sublist in y_train for item in sublist]\n",
    "# x_test_F  = [item for sublist in x_test for item in sublist]\n",
    "# y_test_F  = [item for sublist in y_test for item in sublist]\n",
    "\n",
    "# x_train_w = []\n",
    "# y_train_w = []\n",
    "# x_test_w = []\n",
    "# y_test_w = []\n",
    "\n",
    "# for img in x_train:\n",
    "#     try:\n",
    "#         if img.shape == (224,224,3):\n",
    "#             x_train_w.append(np.array(img))\n",
    "#         else:\n",
    "#             print('wrong',img.shape)\n",
    "#     except:\n",
    "#         print('LOL')\n",
    "\n",
    "# for img in y_train:\n",
    "#     try:\n",
    "#         if img.shape == (224,224,3):\n",
    "#             y_train_w.append(np.array(img))\n",
    "#         else:\n",
    "#             print('wrong',img.shape)\n",
    "#     except:\n",
    "#         print('LOL')\n",
    "\n",
    "# for img in x_test:\n",
    "#     try:\n",
    "#         if img.shape == (224,224,3):\n",
    "#             x_test_w.append(np.array(img))\n",
    "#         else:\n",
    "#             print('wrong',img.shape)\n",
    "#     except:\n",
    "#         print('LOL')\n",
    "\n",
    "# for img in y_test:\n",
    "#     try:\n",
    "#         if img.shape == (224,224,3):\n",
    "#             y_test_w.append(np.array(img))\n",
    "#         else:\n",
    "#             print('wrong',img.shape)\n",
    "#     except:\n",
    "#         print('LOL')\n",
    "\n",
    "# x_train = np.array(x_train_w, dtype=np.float32)\n",
    "# y_train = np.array(y_train_w, dtype=np.float32)\n",
    "# x_test  = np.array(x_test_w, dtype=np.float32)\n",
    "# y_test  = np.array(y_test_w, dtype=np.float32)\n",
    "\n",
    "# img = Image.fromarray(np.array(X_train[0]))\n",
    "# img\n",
    "\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# the data, split between train and test sets\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# print(x_train[0])\n",
    "# print(len(x_train[0]))\n",
    "# im = Image.open(x_train[0])\n",
    "# im.show()\n",
    "# print('before changing')\n",
    "# print('x_train shape:', x_train.shape)\n",
    "# print(x_train.shape[0], 'train samples')\n",
    "# print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "# if K.image_data_format() == 'channels_first':\n",
    "#     x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "#     x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "#     input_shape = (1, img_rows, img_cols)\n",
    "#     print(\"hola\")\n",
    "# else:\n",
    "#     print(\"hola8\")\n",
    "#     x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "#     x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "#     input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# print(x_train[0])\n",
    "# print(len(x_train[0][0][0]))\n",
    "# print(x_train[0].shape)\n",
    "# print(np.zeros((3,3,1)))\n",
    "\n",
    "# im1 = Image.open(\"b.jpeg\").convert('LA')\n",
    "# im1 = Image.open(\"b.jpeg\")\n",
    "# im2=ImageOps.grayscale(im1)\n",
    "# Arr1 = np.array(im1)\n",
    "# Arr2 = np.array(im2)\n",
    "# print('shape of image is',Arr.shape,' value are ',Arr[0][0])\n",
    "# Arr.show()\n",
    "# img = Image.fromarray(Arr)\n",
    "# img.show()    \n",
    "\n",
    "# print(x_train[0].type)\n",
    "# '''\n",
    "# import tensorflow as tf \n",
    "# sess = tf.Session()\n",
    "# K.set_session(sess)\n",
    "\n",
    "# class TFCheckpointCallback(keras.callbacks.Callback):\n",
    "#     def __init__(self,saver,sess):\n",
    "#         self.saver=saver\n",
    "#         self.sess = sess\n",
    "#     def on_epoch_end(self,epoch,logs=None):\n",
    "#         self.saver.save(self.sess,'freeze/checkpoint',global_step=epoch)\n",
    "\n",
    "# tf_saver = tf.train.Saver(max_to_keep=2)\n",
    "# checkpoint_callback = TFCheckpointCallback(tf_saver,sess)\n",
    "# sess.close()\n",
    "# '''\n",
    "\n",
    "\n",
    "# def prepare_graph_for_freezing(model_folder):\n",
    "#     model = createModel6()\n",
    "#     cp = tf.train.get_checkpoint_state(model_folder,latest_filename='cp-0020.ckpt')\n",
    "#     input_cp = cp.model_checkpoint_path\n",
    "#     saver = tf.train.Saver()\n",
    "#     with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "#         K.set_Session(sess)\n",
    "#         saver.restore(sess,input_cp)\n",
    "#         tf.gfile.MakeDirs(model_folder+'freeze')\n",
    "#         saver.save(sess,model_folder+'freeze/checkpoint',global_step=0)\n",
    "\n",
    "# def freeze_graph(model_folder):\n",
    "#     cp = tf.train.get_checkpoint_state(model_folder,latest_filename='cp-0019.ckpt')\n",
    "#     input_cp = cp.model_checkpoint_path\n",
    "#     absolute_model_folder = '/'.join(input_cp.split('/')[:-1])\n",
    "#     output_graph = absolute_model_folder+'/frozen_model.pb'\n",
    "#     output_node_name='output/Softmax'\n",
    "#     clear_devices=True\n",
    "#     new_saver = tf.train.import_meta_graph(input_cp+'.meta',clear_devices=clear_devices)\n",
    "#     graph=tf.get_default_graph()\n",
    "#     input_graph_def = graph.as_graph_def()\n",
    "    \n",
    "#     with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess2:\n",
    "#         new_saver.restore(sess2,input_cp)\n",
    "#         output_graph_def = graph_util.convert_variables_to_constants(sess2,input_graph_def,output_node_name.split(','))\n",
    "#         with tf.gfile.GFile(output_graph,'wb') as f:\n",
    "#             f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "# #tf.reset_default_graph()\n",
    "# #prepare_graph_for_freezing('training/Checkpoints/')\n",
    "# freeze_graph('training/Checkpoints/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(x_train))\n",
    "# print(len(y_train))\n",
    "\n",
    "# print(len(x_test))\n",
    "# print(len(y_test))\n",
    "\n",
    "# a = list(zip(x_train,y_train))\n",
    "# random.shuffle(a)\n",
    "# x_train , y_train = zip(*a)\n",
    "\n",
    "# a = list(zip(x_test,y_test))\n",
    "# random.shuffle(a)\n",
    "# x_test , y_test = zip(*a)\n",
    "# del a\n",
    "\n",
    "# x_train = np.array(list(x_train), dtype=np.float16)\n",
    "# y_train = np.array(list(y_train), dtype=np.float16)\n",
    "# x_test  = np.array(list(x_test), dtype=np.float16)\n",
    "# y_test  = np.array(list(y_test), dtype=np.float16)\n",
    "# y_train = keras.utils.np_utils.to_categorical(y_train, 20)\n",
    "# y_test = keras.utils.np_utils.to_categorical(y_test, 20)\n",
    "\n",
    "# # Normalization\n",
    "\n",
    "# x_train /= 255;\n",
    "# x_test /= 255;\n",
    "\n",
    "# # Saving train and test set in a file\n",
    "\n",
    "# np.save('x_train.npy',x_train)\n",
    "# np.save('y_train.npy',y_train)\n",
    "# np.save('x_test.npy',x_test)\n",
    "# np.save('y_test.npy',y_test)\n",
    "\n",
    "# # Loading Train and Test Set\n",
    "\n",
    "# x_train = np.load('x_train.npy')\n",
    "# y_train = np.load('y_train.npy')\n",
    "# x_test  = np.load('x_test.npy')\n",
    "# y_test  = np.load('y_test.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
